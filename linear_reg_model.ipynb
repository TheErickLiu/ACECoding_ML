{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Week 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Titanic dataset\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "\n",
    "# Display the shape and the first few rows of the dataset\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant features and target variable\n",
    "\n",
    "# 'Survived' is the column we want to predict (1 = survived, 0 = did not survive)\n",
    "target = \"Survived\"\n",
    "\n",
    "# We'll use a subset of commonly available and useful columns\n",
    "features = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Embarked\"]\n",
    "\n",
    "# Drop rows where the target (Survived) is missing\n",
    "df = df.dropna(subset=[target])\n",
    "\n",
    "# Define our features (X) and labels (y)\n",
    "X = df[features]\n",
    "y = df[target]\n",
    "\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate categorical and numerical features\n",
    "cat_features = [\"Sex\", \"Embarked\"]\n",
    "num_features = [\"Pclass\", \"Age\", \"SibSp\", \"Parch\", \"Fare\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build preprocessing pipelines\n",
    "\n",
    "# Pipeline for numerical data:\n",
    "# - SimpleImputer replaces missing values with the median\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\"))\n",
    "])\n",
    "\n",
    "# Pipeline for categorical data:\n",
    "# - SimpleImputer fills missing categories with the most frequent value\n",
    "# - OneHotEncoder converts categories into binary indicator columns\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\"))\n",
    "])\n",
    "\n",
    "# Combine both transformations using ColumnTransformer\n",
    "# This ensures each type of column is processed correctly\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, num_features),\n",
    "        (\"cat\", categorical_transformer, cat_features)\n",
    "    ])\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training and testing sets\n",
    "\n",
    "# The training set is used to fit the model.\n",
    "# The testing set is used to evaluate performance on unseen data.\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(\"Training set size:\", X_train.shape)\n",
    "print(\"Test set size:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train (fit) the model\n",
    "model.fit(X_train, y_train)\n",
    "print(\"Model training complete!\")\n",
    "\n",
    "# Predict survival likelihoods on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compute the R² score, a measure of how well the model fits the data\n",
    "# (1.0 = perfect prediction, 0 = no correlation)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(f\"Model R² score on test set: {r2:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a sample prediction\n",
    "\n",
    "example_passenger = pd.DataFrame([{\n",
    "    \"Pclass\": 3,\n",
    "    \"Sex\": \"male\",\n",
    "    \"Age\": 25,\n",
    "    \"SibSp\": 0,\n",
    "    \"Parch\": 0,\n",
    "    \"Fare\": 7.25,\n",
    "    \"Embarked\": \"S\"\n",
    "}])\n",
    "\n",
    "predicted_survival = model.predict(example_passenger)[0]\n",
    "\n",
    "print(f\"Predicted likelihood of survival: {predicted_survival:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
